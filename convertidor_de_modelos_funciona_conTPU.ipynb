{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jigmam/reactllm/blob/main/convertidor_de_modelos_funciona_conTPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-1JOMWzHlgO",
        "outputId": "d5c74b18-e799-46b7-a3ff-e7ddced64d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U keras>=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIqFWXonHhrx"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC830_ObGMvd"
      },
      "outputs": [],
      "source": [
        "saved_model_dir = '/content/drive/MyDrive/modelos/gemma'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWegrLjNHIp-"
      },
      "outputs": [],
      "source": [
        "loaded_model = keras_nlp.models.GemmaTokenizer.from_preset(saved_model_dir,dtype=\"bfloat16\", load_weights=True )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la configuración del tokenizador en formato JSON\n",
        "config_json = loaded_model.get_config()\n",
        "\n",
        "# Guardar la configuración en un archivo .model\n",
        "with open('/content/drive/MyDrive/modelos/tokenizer2.model', 'w') as model_file:\n",
        "     model_file.write(str(config_json))"
      ],
      "metadata": {
        "id": "4RlCJ6I_5CRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NdY2FAcejdq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpRIvgCXv1Cn"
      },
      "outputs": [],
      "source": [
        "model = loaded_model.backbone\n",
        "print(\"<======= EXPORTING =====>\")\n",
        "\n",
        "export_archive = keras.export.ExportArchive()\n",
        "print(\"<======= TRACKING =====>\")\n",
        "\n",
        "export_archive.track(model)\n",
        "export_archive.add_endpoint(\n",
        "    name=\"serve\",\n",
        "    fn=model.call,\n",
        "    input_signature=[{\n",
        "        \"token_ids\": tf.TensorSpec(shape=(None, 3), dtype=tf.float32),\n",
        "        \"padding_mask\": tf.TensorSpec(shape=(None, 3), dtype=tf.float32),\n",
        "    }],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SRWKSlVIv3pD"
      },
      "outputs": [],
      "source": [
        "export_archive.write_out('gemma_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaQQuy3Oku2l"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsgD86-lwEXe"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model('gemma_2/')\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('/content/drive/MyDrive/modelos/model-quantize.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai3MIT4y1eU3"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1zJSj94gmfRYrNXS2IeCicaSrKCzvqR-Q",
      "authorship_tag": "ABX9TyNGQ2+QoxrskfCNNNL0Ls71",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}